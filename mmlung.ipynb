{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output, display\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipe_scripts.input_parser import *\n",
    "from pipe_scripts.feature_extraction import *\n",
    "from pipe_scripts.widget_scripts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder where .xls files are present for Spirometric readings \n",
    "\n",
    "ground_truth_folder = #ground_truth\n",
    "#The folder for recordings for individual task\n",
    "tasks_folder =  #tasks\n",
    "\n",
    "#Task name\n",
    "task_name = 'cough'\n",
    "\n",
    "tasks = None\n",
    "\n",
    "#This is a dictionary for location of all the target variables in the xls file\n",
    "cell_locations = {'FVC': 'B23', 'FEV1': 'B24', 'FEV1/FVC': 'B25'}\n",
    "\n",
    "tasks_dict = {\n",
    "            'Shallow_Breath': {\n",
    "                                'folder': '10_3_shallowclean',\n",
    "                                'suffix': 'shallowbreath'},\n",
    "            'Rainbow': {\n",
    "                                'folder': '11_4_rainbow', \n",
    "                                'suffix': 'rainbow'},\n",
    "            'Describe_Sth': {\n",
    "                                'folder': '12_5_describe_sth',\n",
    "                                 'suffix': 'describesth'},\n",
    "            'Long': {\n",
    "                                'folder': '13_6_long', \n",
    "                                'suffix': 'long'},\n",
    "            'Short_1': {\n",
    "                                'folder': '14_6_short1', \n",
    "                                'suffix': 'short1'},\n",
    "            'Short_2': {\n",
    "                                'folder': '15_6_short2', \n",
    "                                'suffix': 'short2'},\n",
    "            'Describe_pic': {\n",
    "                                'folder': '16_7_describe_pic', \n",
    "                                'suffix': 'describepic'},\n",
    "            'Action': {\n",
    "                                'folder': '17_8_action', \n",
    "                                'suffix': 'action'},\n",
    "            'Non_Action': {\n",
    "                                'folder': '18_8_nonaction', \n",
    "                                'suffix': 'nonaction'},\n",
    "            'Cough': {\n",
    "                                'folder': '1_1_cough', \n",
    "                                'suffix': 'cough'},\n",
    "            'A_Single': {\n",
    "                                'folder': '2_2_A_single', \n",
    "                                'suffix': 'vowela'},\n",
    "            'E_Single': {\n",
    "                                'folder': '3_2_E_single', \n",
    "                                'suffix': 'vowele'},\n",
    "            'I_Single': {\n",
    "                                'folder': '4_2_I_single', \n",
    "                                'suffix': 'voweli'},\n",
    "            'O_Single': {\n",
    "                                'folder': '5_2_O_single', \n",
    "                                'suffix': 'vowelo'},\n",
    "            'O_Phone_Single': {\n",
    "                                'folder': '6_2_Ophonation_single',\n",
    "                                'suffix': 'vowelophonation'},\n",
    "            'U_Single': {\n",
    "                                'folder': '7_2_U_Single', \n",
    "                                'suffix': 'vowelu'},\n",
    "            'U_Phone_Single': {\n",
    "                                'folder': '8_2_Uphonation_single',\n",
    "                                'suffix': 'voweluphonation'},\n",
    "            'Deep_Breath': {\n",
    "                                'folder': '9_3_deepbreath', \n",
    "                                'suffix': 'deepbreaths'}\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boilerplate code to display and choose target variables to be extracted\n",
    "options_widget = get_gridbox_from_list(tasks_dict.keys())\n",
    "\n",
    "\n",
    "extract_button = widgets.Button(description= 'Extract target values')\n",
    "\n",
    "select_all_button = widgets.Button(description= 'Select All')\n",
    "\n",
    "dataset_df = None\n",
    "\n",
    "\n",
    "\n",
    "def extract_task_files(b):\n",
    "\n",
    "    global tasks \n",
    "    \n",
    "    selected_options = get_selected_checkboxes(options_widget)\n",
    "\n",
    "    tasks = selected_options\n",
    "    clear_output(wait=False)\n",
    "    if len(selected_options) == 0:\n",
    "        print('No tasks selected, please choose an option')\n",
    "        display(options_widget)\n",
    "        display(b)\n",
    "    else:\n",
    "        print(f'Extracting filepaths from tasks folder: {tasks_folder}...')\n",
    "        \n",
    "        global dataset_df \n",
    "        \n",
    "        \n",
    "        #Extracting task filepaths based on choice\n",
    "        dataset_df = extract_file_paths(ground_truth_folder, tasks_folder, tasks_dict, selected_options)\n",
    "        print(f'Task filepaths extracted')\n",
    "\n",
    "\n",
    "def select_all_boxes(b):\n",
    "    for w in options_widget.children:\n",
    "        w.value = True\n",
    "\n",
    "extract_button.on_click(extract_task_files)\n",
    "select_all_button.on_click(select_all_boxes)\n",
    "\n",
    "\n",
    "print('Select the tasks:')\n",
    "display(select_all_button)\n",
    "display(options_widget)\n",
    "display(extract_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "target_names = None\n",
    "variables = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Boilerplate code to display and choose target variables to be extracted\n",
    "options_widget = get_Hbox_from_list(cell_locations.keys())\n",
    "\n",
    "display(options_widget)\n",
    "button = widgets.Button(description= 'Extract target values')\n",
    "\n",
    "def extract_targets(b):\n",
    "    selected_options = get_selected_checkboxes(options_widget)\n",
    "    clear_output(wait=False)\n",
    "    if len(selected_options) == 0:\n",
    "        print('No targets selected, please choose an option')\n",
    "        display(options_widget)\n",
    "        display(b)\n",
    "    else:\n",
    "        print(f'Extracting {selected_options} values from ground truth folder: {ground_truth_folder}...')\n",
    "        cell_coordinates = [cell_locations[x] for x in selected_options]\n",
    "        \n",
    "        global target_names, dataset_df\n",
    "        target_names = selected_options\n",
    "        \n",
    "        #Extracting target variables based on choice\n",
    "        dataset_df[selected_options] = dataset_df.apply(get_target_columns, axis=1, args=(cell_coordinates,), result_type='expand')\n",
    "\n",
    "        print(f'Targets extracted')\n",
    "\n",
    "button.on_click(extract_targets)\n",
    "\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Boilerplate code for choosing features and corresponding aggregates\n",
    "\n",
    "whole_signal_options_widget = get_Hbox_from_list(whole_signal_statistics_dictionary.keys())\n",
    "\n",
    "f_options_pyAudio_widget = get_gridbox_from_list(feature_dictionary_pyAudio.keys())\n",
    "\n",
    "a_options_widget_pyAudio = get_Hbox_from_list(aggregate_dictionary_pyAudio.keys())\n",
    "\n",
    "coeff_options_widget = get_gridbox_from_list(spectral_coefficient_dictionary.keys())\n",
    "\n",
    "f_options_wavelets_widget = get_gridbox_from_list(feature_dictionary_wavelets.keys())\n",
    "\n",
    "a_options_widget_wavelets = get_gridbox_from_list(aggregate_dictionary_pyAudio.keys())\n",
    "\n",
    "button = widgets.Button(description= 'Extract Features')\n",
    "\n",
    "select_all_button = widgets.Button(description= 'Select all')\n",
    "\n",
    "def extract_targets(b):\n",
    "\n",
    "    selected_options = {'pyAudio': {\n",
    "                                    'features': get_selected_checkboxes(f_options_pyAudio_widget), 'aggregates': get_selected_checkboxes(a_options_widget_pyAudio)\n",
    "                                    },\n",
    "                        'whole_signal': get_selected_checkboxes(whole_signal_options_widget),\n",
    "                        'coefficients': get_selected_checkboxes(coeff_options_widget),\n",
    "                        'wavelets': {\n",
    "                            'features': get_selected_checkboxes(f_options_wavelets_widget), 'aggregates': get_selected_checkboxes(a_options_widget_wavelets)\n",
    "                        }}\n",
    "\n",
    "    \n",
    "    clear_output(wait=False)\n",
    "\n",
    "    global variables\n",
    "\n",
    "    for task in tasks:\n",
    "        \n",
    "        print(f'Extracting features of task: {task}')\n",
    "\n",
    "        feature_names = get_feature_names(selected_options)\n",
    "\n",
    "        task_columns = [f'{task}_{feature_name}' for feature_name in feature_names]\n",
    "        if(variables is None):\n",
    "            variables =  task_columns.copy()\n",
    "        else:\n",
    "            variables.extend(task_columns)\n",
    "        #Extracting target variables based on choice\n",
    "        dataset_df[task_columns] = dataset_df.progress_apply(extract_features_from_file, axis=1, args=(task, selected_options,), result_type='expand')\n",
    "\n",
    "    print(f'Features extracted: {variables}')\n",
    "\n",
    "\n",
    "def select_all_boxes(b):\n",
    "    for w in whole_signal_options_widget.children:\n",
    "        w.value = True\n",
    "    for w in f_options_pyAudio_widget.children:\n",
    "        w.value = True\n",
    "    for w in a_options_widget_pyAudio.children:\n",
    "        w.value = True\n",
    "    for w in coeff_options_widget.children:\n",
    "        w.value = True\n",
    "    for w in f_options_wavelets_widget.children:\n",
    "        w.value = True\n",
    "    for w in a_options_widget_wavelets.children:\n",
    "        w.value = True    \n",
    "        \n",
    "\n",
    "button.on_click(extract_targets)\n",
    "select_all_button.on_click(select_all_boxes)\n",
    "\n",
    "display(select_all_button)\n",
    "print('Select Whole signal statistics:')\n",
    "display(whole_signal_options_widget)\n",
    "\n",
    "\n",
    "print('Select Short-term features:')\n",
    "display(f_options_pyAudio_widget)\n",
    "print('Select Aggregates for above features:')\n",
    "display(a_options_widget_pyAudio)\n",
    "print('Select coefficients (Ref: https://superkogito.github.io/spafe/v0.2.0/features/_features.html):')\n",
    "display(coeff_options_widget)\n",
    "\n",
    "print('Select features to be extracted from each sub-band after Discrete Wavelet Transform:')\n",
    "display(f_options_wavelets_widget)\n",
    "print('Select aggregates of features extracted from DWT signals:')\n",
    "display(a_options_widget_wavelets)\n",
    "\n",
    "display(button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.to_excel(F'{task_name}_features_testtaa.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pipe_scripts.visualization import plot_metrics\n",
    "from pipe_scripts.model_bank import model_bank\n",
    "\n",
    "import eli5\n",
    "from sklearn import linear_model\n",
    "\n",
    "from numpy.linalg import eigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_df.to_excel(F'{task_name}_features_all.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_scaled = dataset_df[variables]\n",
    "\n",
    "\n",
    "\n",
    "scaler_dict = {\n",
    "    'MinMax': MinMaxScaler,\n",
    "    'Standard': StandardScaler\n",
    "}\n",
    "\n",
    "scaler_options = widgets.RadioButtons(\n",
    "    options=list(scaler_dict.keys()),\n",
    "\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "def scale_features(b):\n",
    "    global dataset_df,X_scaled\n",
    "    scaler_key = scaler_options.get_interact_value()\n",
    "    \n",
    "    scaler = scaler_dict[scaler_key]()\n",
    "    X_scaled[variables] = scaler.fit_transform(X_scaled[variables])\n",
    "\n",
    "    print(f'Features scaled using {scaler_key}')\n",
    "\n",
    "\n",
    "scale_button = widgets.Button(description='Scale Features')\n",
    "scale_button.on_click(scale_features)\n",
    "display(widgets.Label('Select Scaler'))\n",
    "display(scaler_options)\n",
    "display(scale_button)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "reduced_X = None\n",
    "\n",
    "def run_PCA():\n",
    "    pca = PCA(n_components=0.80)\n",
    "    #n_components=0.99\n",
    "    global reduced_X, X_scaled\n",
    "    print(\"SACLED?\", reduced_X)\n",
    "    reduced_X = pca.fit_transform(X_scaled) # << to retain the components in an object\n",
    "\n",
    "    cov_matrix = np.cov(X_scaled, rowvar=False)\n",
    "\n",
    "    # Determine eigenvalues and eigenvectors\n",
    "    egnvalues, egnvectors = eigh(cov_matrix)\n",
    "\n",
    "    # Determine explained variance\n",
    "    #\n",
    "    total_egnvalues = sum(egnvalues)\n",
    "    var_exp = [(i/total_egnvalues) for i in sorted(egnvalues, reverse=True)]\n",
    "    cum_sum_exp = np.cumsum(var_exp)\n",
    "\n",
    "\n",
    "    #pca.explained_variance_ratio_\n",
    "    print ( \"Components = \", pca.n_components_ , \"\\nTotal explained variance = \",\n",
    "        round(pca.explained_variance_ratio_.sum(),5)*100,'%'  )\n",
    "\n",
    "    plt.plot(cum_sum_exp)\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.show()\n",
    "\n",
    "def run_Lasso():\n",
    "    global reduced_X, X_scaled\n",
    "    #Running Lasso regression on first target variable\n",
    "    regressor = linear_model.Lasso(alpha=0.0001,\n",
    "                               positive=True,\n",
    "                               fit_intercept=False, \n",
    "                               max_iter=100000,\n",
    "                               tol=0.00001)\n",
    "    regressor.fit(X_scaled, y = dataset_df[target_names[0]])\n",
    "\n",
    "    print('Feature importance table')\n",
    "    feature_importance_df = eli5.explain_weights_df(regressor, top=-1, feature_names = variables).drop(['target'], axis=1)\n",
    "    display(feature_importance_df)\n",
    "    important_variables = feature_importance_df['feature'].to_list()\n",
    "\n",
    "    reduced_X = X_scaled[important_variables]\n",
    "\n",
    "\n",
    "reduction_dict = {\n",
    "    'PCA': run_PCA,\n",
    "    'Lasso': run_Lasso\n",
    "}\n",
    "\n",
    "\n",
    "reduction_options = widgets.RadioButtons(\n",
    "    options=list(reduction_dict.keys()),\n",
    "    disabled=False)\n",
    "\n",
    "def reduce_features(b):\n",
    "    reduction_key = reduction_options.get_interact_value()\n",
    "    \n",
    "    reduction_dict[reduction_key]()\n",
    "    \n",
    "\n",
    "    print(f'Features reducted using {reduction_key}')\n",
    "\n",
    "reduction_button = widgets.Button(description='Scale Features')\n",
    "reduction_button.on_click(reduce_features)\n",
    "display(widgets.Label('Select Reduction Algorithm'))\n",
    "display(reduction_options)\n",
    "display(reduction_button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reduced_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave one out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_options = [widgets.Checkbox(description=statistic, value=False) for statistic in model_bank.keys()]\n",
    "model_options_widget = widgets.GridBox(model_options, layout=widgets.Layout(grid_template_columns=\"repeat(4, 250px)\"))\n",
    "\n",
    "button = widgets.Button(description= 'Train models')\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['Target', 'Model', 'MSE', 'MAPE', 'R_Squared'])\n",
    "\n",
    "def train_models(b):\n",
    "    #clear_output(wait=False)\n",
    "\n",
    "    print('R2 values not calculated for Leave one out validation.')\n",
    "\n",
    "    models = [w.description for w in model_options_widget.children if w.value]\n",
    "    fig, axs = plt.subplots(ncols=len(target_names), nrows=len(models), figsize=(5*len(target_names), 5*len(models)), constrained_layout=True)\n",
    "    fig.suptitle(f'Prediction vs Actual distributions for {tasks}', fontsize=16)\n",
    "\n",
    "    for row, model in tqdm(enumerate(models), leave=True):\n",
    "        for column, target in tqdm(enumerate(target_names), leave=False):\n",
    "            y = dataset_df[target]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "            pipe = Pipeline([(model, model_bank[model]['model']())])\n",
    "            params = {}\n",
    "            for param in model_bank[model]['parameters'].keys():\n",
    "                params[f'{model}__{param}'] = model_bank[model]['parameters'][param]\n",
    "            search = GridSearchCV(pipe, params,n_jobs=3)\n",
    "\n",
    "            search.fit(X_train, y_train)\n",
    "            best_estimator = search.best_estimator_\n",
    "\n",
    "            #define cross-validation method to use\n",
    "            cv = LeaveOneOut()\n",
    "            #use LOOCV to evaluate model\n",
    "            scores = cross_validate(best_estimator, X, y, scoring=[ 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error'], cv=cv)\n",
    "            y_pred = search.predict(X)\n",
    "\n",
    "            mape = scores['test_neg_mean_absolute_percentage_error']\n",
    "            mape = mape[~np.isnan(mape)]\n",
    "            mape = np.abs(mape.mean())\n",
    "\n",
    "\n",
    "            mse = scores['test_neg_mean_squared_error'].mean()\n",
    "            mse = mse[~np.isnan(mse)]\n",
    "            mse = np.abs(mse.mean())\n",
    "            #As a null value since test data is of size 1 which is not good for r2 calculations\n",
    "            r2 = -10\n",
    "\n",
    "            metrics_df.loc[len(metrics_df.index)] = [target, model, mse, mape, r2]\n",
    "\n",
    "            if(len(models)>1 & len(target_names)>1):\n",
    "                axis = axs[row, column]\n",
    "\n",
    "            elif(len(models)==len(target_names)):\n",
    "                axis = axs\n",
    "            elif(len(models)==1):\n",
    "                axis = axs[column]\n",
    "            elif(len(target_names)==1):\n",
    "                axis = axs[row]\n",
    "\n",
    "            # plotting both distibutions on the same figure\n",
    "            fig = sns.kdeplot(y_pred, shade=True, color=\"red\", legend='Predicted', ax=axis)\n",
    "            fig = sns.kdeplot(y_test, shade=True, color=\"blue\", legend='Actual', ax=axis)\n",
    "\n",
    "            axis.title.set_text(f'{model} on {target}')\n",
    "\n",
    "            axis.legend(title='Legend', loc='upper right', labels=['Predicted', 'Actual'])\n",
    "\n",
    "    plot_metrics(metrics_df, tasks, no_r2 = True)\n",
    "    plt.show()\n",
    "\n",
    "button.on_click(train_models)\n",
    "\n",
    "print('Select models:')\n",
    "display(model_options_widget)\n",
    "display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 80/20 Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_options = [widgets.Checkbox(description=statistic, value=False) for statistic in model_bank.keys()]\n",
    "model_options_widget = widgets.GridBox(model_options, layout=widgets.Layout(grid_template_columns=\"repeat(4, 250px)\"))\n",
    "\n",
    "button = widgets.Button(description= 'Train models')\n",
    "\n",
    "metrics_df = pd.DataFrame(columns=['Target', 'Model', 'MSE', 'MAPE', 'R_Squared'])\n",
    "\n",
    "def train_models(b):\n",
    "    #clear_output(wait=False)\n",
    "\n",
    "    models = [w.description for w in model_options_widget.children if w.value]\n",
    "    fig, axs = plt.subplots(ncols=len(target_names), nrows=len(models), figsize=(5*len(target_names), 5*len(models)), constrained_layout=True)\n",
    "    fig.suptitle(f'Prediction vs Actual distributions for {tasks}', fontsize=16)\n",
    "\n",
    "    for row, model in tqdm(enumerate(models), leave=True):\n",
    "        for column, target in tqdm(enumerate(target_names), leave=False):\n",
    "            y = dataset_df[target]\n",
    "            #Test train split is 20/80\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "            pipe = Pipeline([ (model, model_bank[model]['model']())])\n",
    "            params = {}\n",
    "            for param in model_bank[model]['parameters'].keys():\n",
    "                params[f'{model}__{param}'] = model_bank[model]['parameters'][param]\n",
    "            search = GridSearchCV(pipe, params, n_jobs=3)\n",
    "            search.fit(X_train, y_train)\n",
    "            y_pred = search.predict(X_test)\n",
    "\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred) \n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            metrics_df.loc[len(metrics_df.index)] = [target, model, mse, mape, r2]\n",
    "\n",
    "            if(len(models)>1 & len(target_names)>1):\n",
    "                axis = axs[row, column]\n",
    "            elif(len(models)==1):\n",
    "                axis = axs[column]\n",
    "            elif(len(target_names)==1):\n",
    "                axis = axs[row]\n",
    "\n",
    "            # plotting both distibutions on the same figure\n",
    "            fig = sns.kdeplot(y_pred, shade=True, color=\"red\", legend='Predicted', ax=axis)\n",
    "            fig = sns.kdeplot(y_test, shade=True, color=\"blue\", legend='Actual', ax=axis)\n",
    "\n",
    "            axis.title.set_text(f'{model} on {target}')\n",
    "\n",
    "            axis.legend(title='Legend', loc='upper right', labels=['Predicted', 'Actual'])\n",
    "\n",
    "    plot_metrics(metrics_df, tasks, no_r2 = False)\n",
    "    plt.show()\n",
    "\n",
    "button.on_click(train_models)\n",
    "\n",
    "print('Select models:')\n",
    "display(model_options_widget)\n",
    "display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "x = range(10)\n",
    "for n in x:\n",
    "    \n",
    "\n",
    "    metrics_df = pd.DataFrame(columns=['Target', 'Model', 'MSE', 'MAPE', 'R_Squared'])\n",
    "\n",
    "    models = [w.description for w in model_options_widget.children if w.value]\n",
    "\n",
    "    for row, model in tqdm(enumerate(models), leave=True):\n",
    "        for column, target in tqdm(enumerate(target_names), leave=False):\n",
    "            y = dataset_df[target]\n",
    "            #Test train split is 20/80\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "            pipe = Pipeline([ (model, model_bank[model]['model']())])\n",
    "            params = {}\n",
    "            for param in model_bank[model]['parameters'].keys():\n",
    "                params[f'{model}__{param}'] = model_bank[model]['parameters'][param]\n",
    "            search = GridSearchCV(pipe, params, n_jobs=3)\n",
    "            search.fit(X_train, y_train)\n",
    "            y_pred = search.predict(X_test)\n",
    "\n",
    "            mape = mean_absolute_percentage_error(y_test, y_pred) \n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "            ##metrics_df is where the matrix has the reauslts \n",
    "            metrics_df.loc[len(metrics_df.index)] = [target, model, mse, mape, r2]\n",
    "            #dataframe_collection[n] = pd.DataFrame(metrics_df, columns=['Target', 'Model', 'MSE', 'MAPE', 'R_Squared'])\n",
    "    metrics_df.to_excel(f'./{task_name}_{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}.xlsx')\n",
    "\n",
    "\n",
    "    #scores = [ {'model': 'LR', 'scores': [target, model, mse, mape, r2]}, {'model': 'LSTM', 'scores': [target, model, mse, mape, r2]} ]    \n",
    "    \n",
    "#     from datetime import datetime\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = metrics_df\n",
    "df\n",
    "import glob\n",
    "\n",
    "files = #data files\n",
    "excel_dfs = []\n",
    "for f in files:\n",
    "  df = pd.read_excel(f)\n",
    "  excel_dfs.append(df)\n",
    "    \n",
    "excel_dfs\n",
    "excel_dfs[4]\n",
    "len(excel_dfs)\n",
    "    \n",
    "\n",
    "    \n",
    "mdf =  (\n",
    "    # combine dataframes into a single dataframe\n",
    "    pd.concat(excel_dfs)\n",
    "    # replace 0 values with nan to exclude them from mean calculation\n",
    "    .replace(0, np.nan)\n",
    "    .reset_index()\n",
    "    # group by the row within the original dataframe\n",
    "    .groupby(\"index\")\n",
    "    # calculate the mean\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "print(mdf)\n",
    "\n",
    "    \n",
    "sdf =  (\n",
    "    # combine dataframes into a single dataframe\n",
    "    pd.concat(excel_dfs)\n",
    "    # replace 0 values with nan to exclude them from mean calculation\n",
    "    .replace(0, np.nan)\n",
    "    .reset_index()\n",
    "    # group by the row within the original dataframe\n",
    "    .groupby(\"index\")\n",
    "    # calculate the mean\n",
    "    .std()\n",
    ")\n",
    "\n",
    "print(sdf)\n",
    "\n",
    "\n",
    "vdf =  (\n",
    "    # combine dataframes into a single dataframe\n",
    "    pd.concat(excel_dfs)\n",
    "    # replace 0 values with nan to exclude them from mean calculation\n",
    "    .replace(0, np.nan)\n",
    "    .reset_index()\n",
    "    # group by the row within the original dataframe\n",
    "    .groupby(\"index\")\n",
    "    # calculate the mean\n",
    "    .var()\n",
    ")\n",
    "\n",
    "print(vdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c28da407b5413b3940d87ecdae5ea8ce0c2929d84f560e9f5daaaa2573d53e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
